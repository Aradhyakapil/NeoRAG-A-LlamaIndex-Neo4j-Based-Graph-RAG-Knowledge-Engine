{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiFkokrjsBhjAw8vOTx+Ej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aradhyakapil/NeoRAG-A-LlamaIndex-Neo4j-Based-Graph-RAG-Knowledge-Engine/blob/main/Knowledge_graph_rag_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC6Us6RixTKn"
      },
      "outputs": [],
      "source": [
        "# ─── 1. Install Dependencies ───────────────────────────────────────────────────\n",
        "# core llama‑index + Neo4j driver + OpenAI client\n",
        "!pip install llama-index neo4j openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-graph-stores-neo4j\n"
      ],
      "metadata": {
        "id": "PjNXgYdg3DPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
        "from llama_index.core import StorageContext\n",
        "from google.colab import userdata\n",
        "# ─── 2. Set Up Environment ─────────────────────────────────────────────────────\n",
        "import os, logging, sys\n",
        "\n",
        "# 2a. OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# 2b. Neo4j AuraDB Free credentials\n",
        "os.environ[\"NEO4J_URI\"]      = userdata.get(\"NEO4J_URI\")\n",
        "os.environ[\"NEO4J_USER\"]     = \"neo4j\"\n",
        "os.environ[\"NEO4J_PASSWORD\"] = userdata.get(\"NEO4J_PASSWORD\")\n",
        "\n",
        "# 2c. Logging (optional, but helpful)\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "# ─── 3. Define LLM & Settings ─────────────────────────────────────────────────\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "Settings.chunk_size = 512\n"
      ],
      "metadata": {
        "id": "QTxqqYxDy7Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ─── 4. Connect to AuraDB via Neo4jPGStore ────────────────────────────────────\n",
        "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "# Pull creds from env\n",
        "uri      = os.environ[\"NEO4J_URI\"]\n",
        "username = os.environ[\"NEO4J_USER\"]\n",
        "password = os.environ[\"NEO4J_PASSWORD\"]\n",
        "\n",
        "# Instantiate the Neo4j-backed graph store\n",
        "graph_store = Neo4jPropertyGraphStore(\n",
        "    url=uri,\n",
        "    username=username,\n",
        "    password=password,\n",
        ")\n",
        "\n",
        "# Wrap into a StorageContext for use by LlamaIndex\n",
        "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
      ],
      "metadata": {
        "id": "hHmxGqCN3Olm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-readers-wikipedia llama-index-readers-web\n"
      ],
      "metadata": {
        "id": "Y6c3tgnr4sWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "_-4nmX__DXcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from llama_index.core.schema import Document\n",
        "# 1. Pull one or more Wikipedia articles\n",
        "raw_wiki_docs = WikipediaReader().load_data(pages=[\"Peter Quill (Marvel Cinematic Universe)\"])\n",
        "wiki_docs = []\n",
        "for doc in raw_wiki_docs:\n",
        "    short_text = doc.text[:10000]\n",
        "    wiki_docs.append(Document(text=short_text, metadata=doc.metadata))\n",
        "# 2. Scratch‑pad: fetch arbitrary URLs\n",
        "urls = [\"https://en.wikipedia.org/wiki/Peter_Quill_(Marvel_Cinematic_Universe)\"]\n",
        "web_docs = SimpleWebPageReader().load_data(urls=urls)\n",
        "\n",
        "# 3. Combine into one list\n",
        "documents = wiki_docs\n"
      ],
      "metadata": {
        "id": "qoE4APxtxfyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-graph-stores-neo4j neo4j\n"
      ],
      "metadata": {
        "id": "tG7rAt2KFEK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dtbuuQaGVzi",
        "outputId": "9aae1c83-c022-445d-bdc9-63ce493d3a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import PropertyGraphIndex, StorageContext\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "kg_index = PropertyGraphIndex.from_documents(\n",
        "    documents,\n",
        "    property_graph_store=graph_store,   # ← tell it to use Neo4j\n",
        "    storage_context=storage_context,\n",
        "    show_progress=True,\n",
        ")\n",
        "# Push into AuraDB\n",
        "#kg_index.storage_context.graph_store.persist_graph(kg_index.graph)\n"
      ],
      "metadata": {
        "id": "8wFA8h5cxbxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ─── 6. Create a Graph‑RAG Retriever & QueryEngine ───────────────────────────\n",
        "#from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "# Create retriever from graph index (recommended way now)\n",
        "retriever = kg_index.as_retriever(\n",
        "    include_text=True,\n",
        "    verbose=True,\n",
        ")\n",
        "# Create query engine\n",
        "query_engine = RetrieverQueryEngine.from_args(retriever=retriever)\n"
      ],
      "metadata": {
        "id": "QeeHf2s9xa7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ─── 7. Run Your Queries ──────────────────────────────────────────────────────\n",
        "# Simple sync query\n",
        "response = query_engine.query(\"Tell me about Peter Quill?\")\n",
        "print(response)\n",
        "\n",
        "# Async query example (if you’re in an async context)\n",
        "# response = await query_engine.aquery(\"What publishers are associated with Peter Quill?\")\n",
        "# print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpI5CyoN3TCv",
        "outputId": "6e41c6ca-e5ea-4906-87ae-f1f8022285ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peter Quill, also known as Star-Lord, is a fictional character portrayed by Chris Pratt in the Marvel Cinematic Universe. He was born in 1980 in St. Charles, Missouri, to a human mother named Meredith and a Celestial father named Ego. After witnessing his mother's death from cancer, he ran away and was abducted by the Ravagers, a mercenary group led by Yondu Udonta, who raised him as a surrogate son.\n",
            "\n",
            "Quill becomes the leader of the Guardians of the Galaxy, a team formed to stop Ronan the Accuser from destroying Xandar. Throughout his journey, he discovers his Celestial heritage and develops a romantic relationship with Gamora. He plays a significant role in the conflict against Thanos, which leads to Gamora's death and his own temporary demise during the Blip. Quill is later resurrected by the Avengers and participates in the final battle against Thanos.\n",
            "\n",
            "In his adventures, Quill and the Guardians face various challenges, including defeating the High Evolutionary. Eventually, he leaves the Guardians to return to Earth, where he reunites with his grandfather. As of 2024, Quill has appeared in six films and a television special, with his character receiving positive reception.\n"
          ]
        }
      ]
    }
  ]
}